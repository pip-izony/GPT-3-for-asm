{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pip-izony/GPT-3-for-asm/blob/main/GPT_3_for_asm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKKa2ZMeCFp1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "948cdf3e-bf09-44a0-f940-1f016081e327"
      },
      "source": [
        "!pip install openai"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.23.0.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.2.0.62-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 55.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from openai) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2022.6.15)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.23.0-py3-none-any.whl size=54478 sha256=a486542b021f49060bae34e2f7322176250626832623c54b494db03eb437a23e\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/d5/31/f9f67660319d89e4f54501d27b1e90f88a3309c42ea4fd734c\n",
            "Successfully built openai\n",
            "Installing collected packages: pandas-stubs, openai\n",
            "Successfully installed openai-0.23.0 pandas-stubs-1.2.0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QRw2rcTh_7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3f06f1-d99d-429a-e82a-f2043b1c3785"
      },
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 9,604 kB of archives.\n",
            "After this operation, 29.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-nanum all 20170925-1 [9,604 kB]\n",
            "Fetched 9,604 kB in 3s (3,235 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 155569 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...\n",
            "Unpacking fonts-nanum (20170925-1) ...\n",
            "Setting up fonts-nanum (20170925-1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMvIhur-iH8q"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', family='NanumBarunGothic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ0zo2j-CH7k"
      },
      "source": [
        "import json\n",
        "import openai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LsGdISjCH-U"
      },
      "source": [
        "openai.api_key = \"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\"\n",
        "response = openai.Completion.create(engine=\"davinci\", prompt=\"This is a test\", max_tokens=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sitf8mRCICf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c11653b0-6627-416b-b789-89b6b2f93f42"
      },
      "source": [
        "!git clone https://github.com/shreyashankar/gpt3-sandbox.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gpt3-sandbox'...\n",
            "remote: Enumerating objects: 2532, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 2532 (delta 4), reused 1 (delta 0), pack-reused 2518\u001b[K\n",
            "Receiving objects: 100% (2532/2532), 5.44 MiB | 19.41 MiB/s, done.\n",
            "Resolving deltas: 100% (746/746), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOZhLtd4CII-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f48311-cf01-4d1b-a596-6d5b7f323db9"
      },
      "source": [
        "cd gpt3-sandbox"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt3-sandbox\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEcjFHtGDK0Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b64da167-6334-4a4a-af78-ddc8ad336500"
      },
      "source": [
        "!pip install -r api/requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting astroid==2.4.2\n",
            "  Downloading astroid-2.4.2-py3-none-any.whl (213 kB)\n",
            "\u001b[K     |████████████████████████████████| 213 kB 30.9 MB/s \n",
            "\u001b[?25hCollecting certifi==2020.6.20\n",
            "  Downloading certifi-2020.6.20-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 48.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from -r api/requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r api/requirements.txt (line 4)) (7.1.2)\n",
            "Collecting Flask==1.1.2\n",
            "  Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from -r api/requirements.txt (line 6)) (2.10)\n",
            "Requirement already satisfied: itsdangerous==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r api/requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: Jinja2==2.11.3 in /usr/local/lib/python3.7/dist-packages (from -r api/requirements.txt (line 8)) (2.11.3)\n",
            "Collecting MarkupSafe==1.1.1\n",
            "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl (33 kB)\n",
            "Collecting openai==0.2.4\n",
            "  Downloading openai-0.2.4.tar.gz (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 61.8 MB/s \n",
            "\u001b[?25hCollecting pylint==2.5.3\n",
            "  Downloading pylint-2.5.3-py3-none-any.whl (324 kB)\n",
            "\u001b[K     |████████████████████████████████| 324 kB 63.7 MB/s \n",
            "\u001b[?25hCollecting python-dotenv==0.14.0\n",
            "  Downloading python_dotenv-0.14.0-py2.py3-none-any.whl (17 kB)\n",
            "Collecting requests==2.27.1\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six==1.15.0 in /usr/local/lib/python3.7/dist-packages (from -r api/requirements.txt (line 14)) (1.15.0)\n",
            "Collecting urllib3==1.26.5\n",
            "  Downloading urllib3-1.26.5-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 71.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Werkzeug==1.0.1 in /usr/local/lib/python3.7/dist-packages (from -r api/requirements.txt (line 16)) (1.0.1)\n",
            "Collecting typed-ast<1.5,>=1.4.0\n",
            "  Downloading typed_ast-1.4.3-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
            "\u001b[K     |████████████████████████████████| 743 kB 60.8 MB/s \n",
            "\u001b[?25hCollecting lazy-object-proxy==1.4.*\n",
            "  Downloading lazy_object_proxy-1.4.3-cp37-cp37m-manylinux1_x86_64.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt~=1.11 in /usr/local/lib/python3.7/dist-packages (from astroid==2.4.2->-r api/requirements.txt (line 1)) (1.14.1)\n",
            "Collecting isort<5,>=4.2.5\n",
            "  Downloading isort-4.3.21-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.1 MB/s \n",
            "\u001b[?25hCollecting mccabe<0.7,>=0.6\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: toml>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pylint==2.5.3->-r api/requirements.txt (line 11)) (0.10.2)\n",
            "Collecting charset-normalizer~=2.0.0\n",
            "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.2.4-py3-none-any.whl size=170708 sha256=48b1ea2535140e36d3237822066fe1f0e398c09bbc7db3424f4a19554335a960\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/08/b7/ac5e799acddcebd3b8bff44fff681cc7626080a477fae8b56f\n",
            "Successfully built openai\n",
            "Installing collected packages: urllib3, typed-ast, MarkupSafe, lazy-object-proxy, charset-normalizer, certifi, requests, mccabe, isort, astroid, python-dotenv, pylint, openai, Flask\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 2.1.1\n",
            "    Uninstalling charset-normalizer-2.1.1:\n",
            "      Successfully uninstalled charset-normalizer-2.1.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.6.15\n",
            "    Uninstalling certifi-2022.6.15:\n",
            "      Successfully uninstalled certifi-2022.6.15\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 0.23.0\n",
            "    Uninstalling openai-0.23.0:\n",
            "      Successfully uninstalled openai-0.23.0\n",
            "  Attempting uninstall: Flask\n",
            "    Found existing installation: Flask 1.1.4\n",
            "    Uninstalling Flask-1.1.4:\n",
            "      Successfully uninstalled Flask-1.1.4\n",
            "Successfully installed Flask-1.1.2 MarkupSafe-1.1.1 astroid-2.4.2 certifi-2020.6.20 charset-normalizer-2.0.12 isort-4.3.21 lazy-object-proxy-1.4.3 mccabe-0.6.1 openai-0.2.4 pylint-2.5.3 python-dotenv-0.14.0 requests-2.27.1 typed-ast-1.4.3 urllib3-1.26.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "openai",
                  "requests",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "EALOO7Xqedxn",
        "outputId": "3619a458-ec13-4c81-e2bf-37b606718ca8"
      },
      "source": [
        "from api import GPT,Example\n",
        "gpt = GPT(temperature=0.1, max_tokens=400)\n",
        "\n",
        "gpt.add_example(Example(\"payload\",\n",
        "\"payload:\\n\\\n",
        "  pop rsi\\n\\\n",
        "  mov rcx, len\\n\\\n",
        "  lea rdi, [r15 + 3001]\\n\\\n",
        "  .decode:\\n\\\n",
        "    lodsb\\n\\\n",
        "    sub  al, 50\\n\\\n",
        "    xor  al, 5\\n\\\n",
        "    stosb\\n\\\n",
        "    loop .decode\\n\\\n",
        "  lea rsi, [r15 + 3001]\\n\\\n",
        "  mov rax, SYS_WRITE\\n\\\n",
        "  mov rdi, STDOUT\\n\\\n",
        "  mov rdx, len\\n\\\n",
        "  syscall\\n\\\"))\n",
        "\n",
        "prompt = \"Print What_Is_Your_Plan\"\n",
        "output = gpt.submit_request(prompt)\n",
        "output.choices[0]['text']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'output: section .data\\ninput_str db \"What_Is_Your_Plan\", 0x0A\\nsection .text\\ninput_str_length db 2\\nglobal _start\\n_start:\\nmov rax, 1\\nmov rdi, 1\\nmov rsi, input_str\\nmov rdx, input_str_length\\nlea rsi, input_str_length\\nmov rdx, strlen(input_str)\\ninput_loop:\\ncmp rdx, 0\\nje _exit\\nmov rax, 1\\nmov rdi, 1\\nmov rsi, input_str\\nmov rdx, 0\\n\\nje input_loop\\nmov rax, 60\\nmov rdi, 0\\nsyscall\\ninput_loop\\ninput_loop:\\nmov rax, 60\\nmov rdi, 0\\nsyscall\\n_exit:\\nmov rax, 60\\nmov rdi, 0\\nsyscall\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 새 섹션"
      ],
      "metadata": {
        "id": "nbs-D-ecE6bJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 새 섹션"
      ],
      "metadata": {
        "id": "lvKUaIxzE6zl"
      }
    }
  ]
}